{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python script below performs the following configuration tasks:\n",
    "\n",
    "Initializes a SparkSession with the necessary .jar files for Snowflake integration.\n",
    "\n",
    "Loads the Snowflake JDBC and Spark-Snowflake connector using the spark.jars property.\n",
    "\n",
    "Sets up the Spark context for PySpark operations.\n",
    "\n",
    "Prepares the environment to read/write between Spark and Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all necessary classes and modules.\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import findspark\n",
    "\n",
    "#Initalizing the findspark module to recognize the spark installed on my system\n",
    "findspark.init()\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"SpotifyDataNormalization\").config(\"spark.jars\", r\"C:\\spark-3.5.5-bin-hadoop3\\jars\\snowflake-jdbc-3.23.2.jar,C:\\spark-3.5.5-bin-hadoop3\\jars\\spark-snowflake_2.12-3.1.1\").getOrCreate()\n",
    "\n",
    "#Setting snowflake credentials.\n",
    "snowflakeConfig = {\n",
    "    \"sfURL\": \"https://cexmrap-kb36509.snowflakecomputing.com\",\n",
    "    \"sfUser\": os.getenv(\"SNOWFLAKE_USER1\"),\n",
    "    \"sfPassword\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "    \"sfDatabase\": os.getenv(\"SNOWFLAKE_DB1\"),\n",
    "    \"sfSchema\": os.getenv(\"SNOWFLAKE_SCHEMA1\"),\n",
    "    \"sfWarehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE1\"),\n",
    "    \"sfRole\": os.getenv(\"SNOWFLAKE_ROLE1\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python script below performs the following tasks:\n",
    "\n",
    "Converts the contents of the played_at field from Unix Timestamp to a readable Date and Time format.\n",
    "\n",
    "Writes the transformed data to a CSV file.\n",
    "\n",
    "The CSV file will be overwritten each time the script is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+----------------------------------------------------+\n",
      "|artist_name      |played_at          |track_name                                          |\n",
      "+-----------------+-------------------+----------------------------------------------------+\n",
      "|Strings And Heart|2025-03-29 01:30:46|honeydew (praise the Lord)                          |\n",
      "|Strings And Heart|2025-03-29 01:32:49|dopamine                                            |\n",
      "|Strings And Heart|2025-03-29 01:35:48|evergreen love                                      |\n",
      "|Strings And Heart|2025-03-29 01:37:49|bright eyed                                         |\n",
      "|Strings And Heart|2025-03-29 01:42:10|Your Love                                           |\n",
      "|Strings And Heart|2025-03-29 01:45:10|dulce                                               |\n",
      "|Strings And Heart|2025-03-29 01:48:15|rescue                                              |\n",
      "|Rojo             |2025-03-29 01:51:23|Cuando Te Encontré feat. Strings and Heart (En Vivo)|\n",
      "|Strings And Heart|2025-03-29 01:54:55|milk and honey                                      |\n",
      "|Strings And Heart|2025-03-29 01:57:53|evergreen love                                      |\n",
      "|Strings And Heart|2025-03-29 02:00:28|flowers dressed in blue                             |\n",
      "|Strings And Heart|2025-03-29 02:02:31|dopamine                                            |\n",
      "|Josiah Queen     |2025-03-29 02:05:23|love you to death                                   |\n",
      "|Strings And Heart|2025-03-29 02:07:52|if i don't got you                                  |\n",
      "|Strings And Heart|2025-03-29 02:10:10|empty airport                                       |\n",
      "|Strings And Heart|2025-03-29 02:12:11|bright eyed                                         |\n",
      "|Rojo             |2025-03-29 02:16:11|A Tus Pies (Hoy Me Rindo)                           |\n",
      "|Strings And Heart|2025-03-29 02:19:38|more of you                                         |\n",
      "|Strings And Heart|2025-03-29 02:22:25|i'm free                                            |\n",
      "|Strings And Heart|2025-03-29 02:25:22|sunset silhouette                                   |\n",
      "+-----------------+-------------------+----------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read data into a dataframe\n",
    "df = spark.read.option(\"multiline\", \"true\").json(\"all_recent_tracks.json\")\n",
    "\n",
    "# Convert timestamp to normal date and time \n",
    "df = df.withColumn(\"played_at\", F.from_unixtime(F.col(\"played_at\") / 1000, \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "# Creating A CSV file of the transformed data\n",
    "df.coalesce(1).write.option(\"header\", \"true\").mode(\"overwrite\").csv(\"clean_all_tracks.csv\")\n",
    "\n",
    "# Load the transformed data into snowflake database\n",
    "df.write.format(\"snowflake\").options(**snowflakeConfig).option(\"dbtable\", \"all_tracks\").option(\"sfTableCreation\", \"CREATE_IF_NEEDED\").mode(\"append\").save()\n",
    "\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script, although commented out, plays a crucial role in some of our projects. Its intended purpose is to move the necessary CSV file from the folder created by PySpark after the transformation process. The goal is to take the CSV file containing the transformed data and move it to a specific location.\n",
    "\n",
    "Why is it commented out?\n",
    "Some may wonder why this script is commented. The reason is that the name of the file changes each time the script is re-run. Because PySpark generates a new file with a unique name (e.g., part-00001-...), the path of the file keeps changing. Given that the data is intended to keep growing and the file name is dynamic, it wouldn't be feasible to hard-code the path or attempt to manually move the file. This makes it challenging to automate without first addressing the changing file names.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\IFEOMA\\AppData\\Local\\Temp\\ipykernel_8600\\441510881.py:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  \"\"\" import shutil\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' import shutil\\n# Move the part file to desired location\\npart_file = \"clean_tracks.csv\\\\part-00000-e767b6d4-f389-44a7-91b0-dec958759f38-c000.csv\"\\ndestination = \"clean_recent_tracks.csv\"\\nshutil.move(part_file,destination) '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import shutil\n",
    "# Move the part file to desired location\n",
    "part_file = \"clean_tracks.csv\\part-00000-e767b6d4-f389-44a7-91b0-dec958759f38-c000.csv\"\n",
    "destination = \"clean_recent_tracks.csv\"\n",
    "shutil.move(part_file,destination) \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script below performs the following tasks:\n",
    "\n",
    "Trims down the track ID: It extracts only the numbers from the full track ID, which might originally look like spotify:track:{id}. This operation helps focus on the core track ID, removing the unnecessary prefix.\n",
    "\n",
    "Splitting and Indexing: The splitting of the track ID and indexing is used as an exercise to improve skills in working with string manipulation.\n",
    "\n",
    "Converts song duration: The script converts song durations from milliseconds to minutes and seconds for easier readability.\n",
    "\n",
    "Drops the link column: Since the link column was filled with null values, it was deemed unnecessary and dropped to clean up the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+----------------------+----------+-----------------------------------+-------+-------+\n",
      "|artist_name    |duration|id                    |popularity|track_name                         |minutes|seconds|\n",
      "+---------------+--------+----------------------+----------+-----------------------------------+-------+-------+\n",
      "|Claire Leslie  |3:00    |4HR5BN6hc4AmcPO1NK0fgK|45        |24/7                               |3      |0      |\n",
      "|Grace Marr     |2:35    |5BH8UixV8wu3FR5xJksIJN|2         |Belong                             |2      |35     |\n",
      "|Cade Kellam    |4:02    |7LcJx95sWXpqCMLxQJfhMM|46        |Blessed                            |4      |2      |\n",
      "|Forrest Frank  |2:41    |1716cky8w4roZox3AyO1zh|67        |CELEBRATION                        |2      |41     |\n",
      "|Forrest Frank  |2:41    |2YfSEfmGirtcp6C6ZcLelL|57        |CELEBRATION                        |2      |41     |\n",
      "|OAKS           |3:16    |2TUW3yDwsfNcBOtk8RPSqu|27        |Clean                              |3      |16     |\n",
      "|Gabriel Eziashi|13:37   |2SHWUh366VIpgpDHxxtnID|34        |Contemporary Praise Medley - Live  |13     |37     |\n",
      "|Kelly Clarkson |4:08    |3knblvtjbcTtEk0HCiJHZK|53        |Creep - Live                       |4      |8      |\n",
      "|ONE HOUSE      |5:04    |4Cr2oltVAPC6rAUMTgot0M|30        |Down In My Heart                   |5      |4      |\n",
      "|Gabriel Eziashi|2:58    |3zfPYqEqCoO6ud6PMrXqXK|44        |Dry Bones                          |2      |58     |\n",
      "|Dâmares Gomes  |3:18    |1V9AYsVkGvDL0XrkYvUOGv|39        |Even Better                        |3      |18     |\n",
      "|Cade Kellam    |4:54    |4sZLEFie6r4WxCjCUzFv4f|25        |Faithful                           |4      |54     |\n",
      "|Claire Leslie  |2:50    |4PqpoY1wcn4GsM4gKw7lBO|37        |Falling At The Thought Of You      |2      |50     |\n",
      "|Samantha Ebert |3:46    |0KIv0Lho9vsPCj8Sac21IV|54        |Flowers                            |3      |46     |\n",
      "|Alabaster Co.  |5:32    |0FYUGkkaI0OpnHVeH44kjb|16        |For the Beauty of the Earth        |5      |32     |\n",
      "|G.E.S          |3:14    |7fF2rQnUkELUq0AzByzH9K|42        |Free My Mind                       |3      |14     |\n",
      "|G.E.S          |2:10    |5JD1bFe82TNbO4TaJiyGj5|41        |Giving It to You                   |2      |10     |\n",
      "|Paul Tomisin   |7:03    |4ZWMGSggxHp87KTvRoyfFn|45        |Grace Story                        |7      |3      |\n",
      "|sxxnt.         |1:28    |3MuYxyhq6m5OLG6NCA73RX|37        |Great Is Thy Faithfulness (Reprise)|1      |28     |\n",
      "|DKG KIE        |2:44    |6qLrRZYhtWKkanyYOJfl8B|47        |HOLY HUH?                          |2      |44     |\n",
      "+---------------+--------+----------------------+----------+-----------------------------------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading the raw file(json) into the second dataframe \n",
    "df2 = spark.read.option(\"multiline\", \"true\").json(\"all_top_tracks.json\")\n",
    "\n",
    "# Split by \":\" and get just the id which is the last part\n",
    "df2 = df2.withColumn(\"id\", F.split(\"id\", \":\").getItem(2))\n",
    "\n",
    "#Set the duration in milliseconds to nomral minutes and seconds format\n",
    "#Convert to minutes\n",
    "df2 = df2.withColumn(\"minutes\", F.floor(F.col(\"duration\") / 60000))\n",
    "#Get the seconds\n",
    "df2= df2.withColumn(\"seconds\", F.floor((F.col(\"duration\") % 60000) / 1000))\n",
    "#Join the two of them together\n",
    "df2 = df2.withColumn( \"duration\",F.concat_ws(\":\", F.col(\"minutes\"), F.lpad(F.col(\"seconds\").cast(\"string\"), 2, \"0\")))\n",
    "#Removing the link column\n",
    "df2 = df2.drop(\"link\")\n",
    "\n",
    "#Converting the dataframe into a csv file \n",
    "df2.coalesce(1).write.option(\"header\", \"true\").mode(\"overwrite\").csv(\"clean_all_top_tracks.csv\")\n",
    "\n",
    "# Load the transformed data into snowflake database\n",
    "df2.write.format(\"snowflake\").options(**snowflakeConfig).option(\"dbtable\", \"top_tracks\").option(\"sfTableCreation\", \"CREATE_IF_NEEDED\").mode(\"append\").save()\n",
    "\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script below performs the following tasks:\n",
    "\n",
    "Retrieves all contents of the genre column: The genre column in the raw JSON file is an array containing multiple genre values for each track.\n",
    "\n",
    "Extracts all genre values: The script extracts and processes each genre from the array, ensuring all the different genres associated with a track are retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+--------------------------+------------------------------------------------------+\n",
      "|Artistname       |FamousLevel|genre                     |Link                                                  |\n",
      "+-----------------+-----------+--------------------------+------------------------------------------------------+\n",
      "|sxxnt.           |53         |gospel r&b                |https://open.spotify.com/artist/4T0c560DVGr1cAtE3reOP1|\n",
      "|Cade Kellam      |36         |gospel r&b                |https://open.spotify.com/artist/1GWnsRvGpSmKxHOjMQah4k|\n",
      "|Cade Kellam      |36         |christian alternative rock|https://open.spotify.com/artist/1GWnsRvGpSmKxHOjMQah4k|\n",
      "|Claire Leslie    |42         |pop worship               |https://open.spotify.com/artist/5GkuwRdmvp8r48JCPwqM7E|\n",
      "|Claire Leslie    |42         |christian pop             |https://open.spotify.com/artist/5GkuwRdmvp8r48JCPwqM7E|\n",
      "|Claire Leslie    |42         |christian                 |https://open.spotify.com/artist/5GkuwRdmvp8r48JCPwqM7E|\n",
      "|Gabriel Eziashi  |43         |african gospel            |https://open.spotify.com/artist/6sx0dcFppnpZl1HSX6cCqx|\n",
      "|Gabriel Eziashi  |43         |gospel                    |https://open.spotify.com/artist/6sx0dcFppnpZl1HSX6cCqx|\n",
      "|Gabriel Eziashi  |43         |worship                   |https://open.spotify.com/artist/6sx0dcFppnpZl1HSX6cCqx|\n",
      "|Bidemi Olaoba    |48         |african gospel            |https://open.spotify.com/artist/6zgGhksQtJmJzAOalAeUSV|\n",
      "|Bidemi Olaoba    |48         |gospel                    |https://open.spotify.com/artist/6zgGhksQtJmJzAOalAeUSV|\n",
      "|Bidemi Olaoba    |48         |worship                   |https://open.spotify.com/artist/6zgGhksQtJmJzAOalAeUSV|\n",
      "|Kenneth Kelly    |27         |gospel r&b                |https://open.spotify.com/artist/0S90F2l4d1G4ZeqVvDLy3q|\n",
      "|Kenneth Kelly    |27         |pop worship               |https://open.spotify.com/artist/0S90F2l4d1G4ZeqVvDLy3q|\n",
      "|Kenneth Kelly    |27         |christian pop             |https://open.spotify.com/artist/0S90F2l4d1G4ZeqVvDLy3q|\n",
      "|Sinmidele        |48         |gospel r&b                |https://open.spotify.com/artist/0xmUZqkqmJfezc0fzyfboj|\n",
      "|Sinmidele        |48         |african gospel            |https://open.spotify.com/artist/0xmUZqkqmJfezc0fzyfboj|\n",
      "|Sinmidele        |48         |gospel                    |https://open.spotify.com/artist/0xmUZqkqmJfezc0fzyfboj|\n",
      "|Strings And Heart|60         |christian folk            |https://open.spotify.com/artist/5lHDypXbNmHTDoFWpSTqXd|\n",
      "|Strings And Heart|60         |christian alternative rock|https://open.spotify.com/artist/5lHDypXbNmHTDoFWpSTqXd|\n",
      "+-----------------+-----------+--------------------------+------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading the raw file(json) into the third dataframe \n",
    "df3 = spark.read.option(\"multiline\", \"true\").json(\"all_top_artists.json\")\n",
    "\n",
    "#Getting all the contents of the genre array\n",
    "df3 = df3.withColumn(\"genre\", F.explode(\"Genre\"))\n",
    "\n",
    "#Converting the dataframe into a csv file \n",
    "df3.coalesce(1).write.option(\"header\", \"true\").mode(\"overwrite\").csv(\"clean_all_top_artists.csv\")\n",
    "\n",
    "# Load the transformed data into snowflake database\n",
    "df3.write.format(\"snowflake\").options(**snowflakeConfig).option(\"dbtable\", \"top_artist\").option(\"sfTableCreation\", \"CREATE_IF_NEEDED\").mode(\"append\").save()\n",
    "\n",
    "df3.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
